"""
Real-time Fraud Detection Dashboard
====================================
Interactive Streamlit application for fraud detection with:
- Overview dashboard with charts and metrics
- Single transaction fraud check
- Customer investigation tools
- Model explainability and insights
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import json
import glob
import os
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
from PIL import Image

# Page configuration
st.set_page_config(
    page_title="Real-time Fraud Detection",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
    <style>
    .big-font {
        font-size:20px !important;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    </style>
    """, unsafe_allow_html=True)

def generate_model_report():
    """Generate comprehensive model report as downloadable content"""
    
    report_content = f"""
         ->  FRAUD DETECTION MODEL - PERFORMANCE REPORT    <-         

Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

1. MODEL INFORMATION

Model Type:              XGBoost Classifier
Training Date:           {model_pipeline.get('training_date', 'N/A')}
Total Features:          {len(feature_names)}
Random State:            {model_pipeline.get('random_state', 42)}

2. PERFORMANCE METRICS

AUPRC (Primary Metric): {metrics.get('auprc', 0):.4f}
ROC-AUC:                {metrics.get('roc_auc', 0):.4f}
Test Samples:           {metrics.get('test_samples', 0):,}
Training Samples:       {metrics.get('train_samples', 0):,}

3. TOP 15 IMPORTANT FEATURES
"""
    
    # Add feature importance if available
    if os.path.exists('artifacts/feature_importance.csv'):
        feat_imp = pd.read_csv('artifacts/feature_importance.csv')
        for idx, row in feat_imp.head(15).iterrows():
            report_content += f"\n{idx+1:2d}. {row['feature']:40s} {row['importance']:.6f}"
    
    report_content += f"""

4. DEPLOYMENT RECOMMENDATIONS

Threshold Settings:
- High Security (Banking):        0.30 - 0.40
- Balanced (E-commerce):          0.45 - 0.55
- Low Friction (High Volume):     0.60 - 0.70

Current Threshold: {threshold:.2f}

Monitoring:
- Retrain model every 30 days
- Monitor daily AUPRC and false positive rate
- Set up alerts for performance degradation
- Log all predictions for audit trail

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Report End
Generated by Fraud Detection System v1.0
¬© 2025 - Made by Jeimeen Chaudhari

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""
    
    return report_content


def get_flagged_transactions(dataframe, threshold, model, scaler, features):
    """Identify and return flagged transactions above threshold"""
    
    if dataframe.empty:
        return pd.DataFrame()
    
    # Prepare features for prediction
    try:
        # Select only the features that exist in both df and feature list
        available_features = [f for f in features if f in dataframe.columns]
        
        if len(available_features) == 0:
            return pd.DataFrame()
        
        X = dataframe[available_features].copy()
        
        # Handle missing features by filling with defaults
        for feature in features:
            if feature not in X.columns:
                X[feature] = 0
        
        # Ensure correct order
        X = X[features]
        
        # Scale and predict
        X_scaled = scaler.transform(X)
        fraud_probs = model.predict_proba(X_scaled)[:, 1]
        
        # Add predictions to dataframe
        result_df = dataframe.copy()
        result_df['fraud_probability'] = fraud_probs
        result_df['fraud_prediction'] = (fraud_probs >= threshold).astype(int)
        result_df['risk_level'] = pd.cut(
            fraud_probs,
            bins=[0, 0.3, 0.5, 0.7, 1.0],
            labels=['Low', 'Medium', 'High', 'Critical']
        )
        
        # Filter only flagged transactions
        flagged = result_df[result_df['fraud_prediction'] == 1].copy()
        
        # Sort by probability (highest risk first)
        flagged = flagged.sort_values('fraud_probability', ascending=False)
        
        # Select relevant columns for export
        export_columns = ['TX_DATETIME', 'CUSTOMER_ID', 'TERMINAL_ID', 'TX_AMOUNT', 
                         'fraud_probability', 'risk_level']
        
        # Add actual fraud label if available
        if 'TX_FRAUD' in flagged.columns:
            export_columns.append('TX_FRAUD')
        
        # Keep only existing columns
        export_columns = [col for col in export_columns if col in flagged.columns]
        
        return flagged[export_columns]
    
    except Exception as e:
        st.error(f"Error generating flagged transactions: {str(e)}")
        return pd.DataFrame()
# ============================================================================
# LOAD MODEL AND DATA
# ============================================================================

@st.cache_resource
def load_model():
    """Load the trained fraud detection model"""
    try:
        with open('fraud_detection_model.pkl', 'rb') as f:
            model_data = pickle.load(f)
        return model_data
    except FileNotFoundError:
        st.error("‚ùå Model file not found! Please run train_fraud_model.py first.")
        st.stop()

@st.cache_data
def load_feature_list():
    """Load feature names"""
    try:
        with open('artifacts/feature_list.json', 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        st.warning("Feature list not found. Using default features.")
        return []

@st.cache_data
def load_metrics():
    """Load training metrics"""
    try:
        with open('artifacts/metrics.json', 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

@st.cache_data
def load_dataset():
    """Load all transaction data from pkl files"""
    data_folder = "data/"
    pkl_files = sorted(glob.glob(os.path.join(data_folder, "*.pkl")))
    
    if not pkl_files:
        return pd.DataFrame()
    
    dfs = []
    for f in pkl_files[:30]:  # Limit to first 30 files for performance
        try:
            df_temp = pd.read_pickle(f)
            dfs.append(df_temp)
        except:
            continue
    
    if dfs:
        df = pd.concat(dfs, ignore_index=True)
        df['TX_DATETIME'] = pd.to_datetime(df['TX_DATETIME'], errors='coerce')
        return df
    return pd.DataFrame()

# Load model and data
model_pipeline = load_model()
model = model_pipeline['model']
scaler = model_pipeline['scaler']
feature_names = model_pipeline['feature_names']
metrics = load_metrics()

# ============================================================================
# SIDEBAR
# ============================================================================

st.sidebar.title("üîç Fraud Detection System By CJ")
st.sidebar.markdown("---")

# Model info
st.sidebar.subheader("Model Information")
st.sidebar.info(f"""
**Model Type:** XGBoost Classifier  
**Features:** {len(feature_names)}  
**Training Date:** {model_pipeline.get('training_date', 'N/A')[:10]}  
**AUPRC:** {metrics.get('auprc', 0):.4f}
""")

def generate_model_report():
    """Generate a comprehensive model report as text"""
    report = []
    report.append("FRAUD DETECTION MODEL REPORT")
    report.append("=" * 50 + "\n")
    
    # Model information
    report.append("MODEL INFORMATION")
    report.append("-" * 20)
    report.append(f"Model Type: XGBoost Classifier")
    report.append(f"Number of Features: {len(feature_names)}")
    report.append(f"Training Date: {model_pipeline.get('training_date', 'N/A')[:10]}")
    report.append("")
    
    # Performance metrics
    report.append("PERFORMANCE METRICS")
    report.append("-" * 20)
    report.append(f"AUPRC: {metrics.get('auprc', 0):.4f}")
    report.append(f"ROC-AUC: {metrics.get('roc_auc', 0):.4f}")
    report.append(f"Test Samples: {metrics.get('test_samples', 0):,}")
    report.append("")
    
    # Feature list
    report.append("FEATURES USED")
    report.append("-" * 20)
    for i, feature in enumerate(feature_names, 1):
        report.append(f"{i}. {feature}")
    
    return "\n".join(report)

# Threshold slider
st.sidebar.markdown("---")
st.sidebar.subheader("Detection Settings")
threshold = st.sidebar.slider(
    "Fraud Probability Threshold",
    min_value=0.0,
    max_value=1.0,
    value=0.5,
    step=0.05,
    help="Transactions with probability above this threshold are flagged as fraudulent"
)

# Advanced options
show_advanced = st.sidebar.checkbox("Show Advanced Charts", value=True)

st.sidebar.markdown("---")
st.sidebar.markdown("### üìä Navigation")
st.sidebar.info("Use the tabs above to navigate between different sections of the dashboard.")

# ============================================================================
# MAIN CONTENT
# ============================================================================

st.title("üîç Real-time Fraud Detection Dashboard")
st.markdown("**Detect fraudulent transactions with machine learning**")
st.markdown("---")

# Create tabs
tab1, tab2, tab3, tab4 = st.tabs([
    "üìä Overview", 
    "üîé Model Check", 
    "üë§ Investigate Customer",
    "üß† Model Explainability"
])

# ============================================================================
# TAB 1: OVERVIEW DASHBOARD
# ============================================================================

with tab1:
    st.header("Overview Dashboard")
    
    # Load dataset
    with st.spinner("Loading transaction data..."):
        df = load_dataset()
    
    if df.empty:
        st.warning("No transaction data available. Please ensure .pkl files are in the data/ folder.")
    else:
        # Key metrics in columns
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Total Transactions",
                f"{len(df):,}",
                delta=None
            )
        
        with col2:
            fraud_count = df['TX_FRAUD'].sum() if 'TX_FRAUD' in df.columns else 0
            fraud_rate = (fraud_count / len(df) * 100) if len(df) > 0 else 0
            st.metric(
                "Fraud Rate",
                f"{fraud_rate:.3f}%",
                delta=f"{fraud_count:,} frauds"
            )
        
        with col3:
            avg_amount = df['TX_AMOUNT'].mean() if 'TX_AMOUNT' in df.columns else 0
            st.metric(
                "Avg Transaction",
                f"${avg_amount:.2f}",
                delta=None
            )
        
        with col4:
            date_range = (df['TX_DATETIME'].max() - df['TX_DATETIME'].min()).days if 'TX_DATETIME' in df.columns else 0
            st.metric(
                "Date Range",
                f"{date_range} days",
                delta=None
            )
        
        st.markdown("---")
        
        # Charts
        if show_advanced and 'TX_DATETIME' in df.columns:
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Transactions Over Time")
                df['date'] = df['TX_DATETIME'].dt.date
                daily_counts = df.groupby('date').size().reset_index(name='count')
                
                fig = px.line(
                    daily_counts, 
                    x='date', 
                    y='count',
                    title='Daily Transaction Volume'
                )
                fig.update_layout(
                    xaxis_title="Date",
                    yaxis_title="Number of Transactions",
                    hovermode='x unified'
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.subheader("Transaction Amount Distribution")
                fig = px.histogram(
                    df,
                    x='TX_AMOUNT',
                    nbins=50,
                    title='Amount Distribution (Log Scale)',
                    log_y=True
                )
                fig.update_layout(
                    xaxis_title="Transaction Amount ($)",
                    yaxis_title="Count (log scale)"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # Hourly heatmap
        if show_advanced and 'TX_DATETIME' in df.columns:
            st.subheader("Fraud Pattern: Hour vs Day of Week")
            
            df['hour'] = df['TX_DATETIME'].dt.hour
            df['day_of_week'] = df['TX_DATETIME'].dt.dayofweek
            
            if 'TX_FRAUD' in df.columns:
                heatmap_data = df.groupby(['day_of_week', 'hour'])['TX_FRAUD'].mean().reset_index()
                heatmap_pivot = heatmap_data.pivot(index='day_of_week', columns='hour', values='TX_FRAUD')
                
                fig = go.Figure(data=go.Heatmap(
                    z=heatmap_pivot.values,
                    x=heatmap_pivot.columns,
                    y=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],
                    colorscale='Reds',
                    text=heatmap_pivot.values,
                    texttemplate='%{text:.3f}',
                    textfont={"size": 10}
                ))
                
                fig.update_layout(
                    title='Fraud Rate by Hour and Day',
                    xaxis_title='Hour of Day',
                    yaxis_title='Day of Week',
                    height=400
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # Model evaluation charts
        st.markdown("---")
        st.subheader("Model Performance")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if os.path.exists('artifacts/confusion_matrix.png'):
                st.image('artifacts/confusion_matrix.png', caption='Confusion Matrix')
        
        with col2:
            if os.path.exists('artifacts/precision_recall_curve.png'):
                st.image('artifacts/precision_recall_curve.png', caption='Precision-Recall Curve')

# ============================================================================
# TAB 2: MODEL CHECK (Single Transaction)
# ============================================================================

with tab2:
    st.header("üîé Check Single Transaction")
    st.markdown("Enter transaction details to check fraud probability")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Transaction Details")
        
        tx_amount = st.number_input(
            "Transaction Amount ($)",
            min_value=0.0,
            max_value=10000.0,
            value=100.0,
            step=10.0
        )
        
        hour = st.slider("Hour of Day", 0, 23, 12)
        
        day_of_week = st.selectbox(
            "Day of Week",
            options=[0, 1, 2, 3, 4, 5, 6],
            format_func=lambda x: ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 
                                   'Friday', 'Saturday', 'Sunday'][x]
        )
        
        is_weekend = 1 if day_of_week >= 5 else 0
        
        st.subheader("Additional Features (Optional)")
        
        cust_avg_amount = st.number_input(
            "Customer Avg Amount",
            min_value=0.0,
            value=50.0,
            help="Average transaction amount for this customer"
        )
        
        cust_tx_count = st.number_input(
            "Customer Total Transactions",
            min_value=0,
            value=10,
            help="Total number of transactions by this customer"
        )
    
    with col2:
        st.subheader("Prediction Result")
        
        if st.button("üîç Check Transaction", type="primary", use_container_width=True):
            # Prepare features
            features_dict = {
                'TX_AMOUNT': tx_amount,
                'amount_log': np.log1p(tx_amount),
                'hour': hour,
                'day_of_week': day_of_week,
                'is_weekend': is_weekend,
                'day_of_month': 15,  # Default
                'month': 4,  # Default
                'cust_avg_amount': cust_avg_amount,
                'cust_std_amount': cust_avg_amount * 0.3,  # Estimate
                'cust_tx_count': cust_tx_count,
                'cust_fraud_count': 0,  # Default
                'terminal_avg_amount': 75.0,  # Default
                'terminal_tx_count': 100,  # Default
                'terminal_fraud_count': 1,  # Default
                'amount_to_cust_avg_ratio': tx_amount / (cust_avg_amount + 1e-5),
                'amount_to_terminal_avg_ratio': tx_amount / 75.0,
                'cust_tx_count_24h': 5,  # Default
                'terminal_tx_count_24h': 20  # Default
            }
            
            # Create DataFrame with correct feature order
            X_input = pd.DataFrame([features_dict])[feature_names]
            
            # Scale and predict
            X_scaled = scaler.transform(X_input)
            fraud_prob = model.predict_proba(X_scaled)[0, 1]
            
            # Display probability
            st.metric("Fraud Probability", f"{fraud_prob:.2%}")
            
            # Progress bar
            st.progress(float(fraud_prob))
            
            # Risk assessment
            if fraud_prob > threshold:
                st.error("üö® **HIGH RISK** - This transaction should be reviewed!")
                st.warning(f"Probability ({fraud_prob:.2%}) exceeds threshold ({threshold:.2%})")
            elif fraud_prob > threshold * 0.7:
                st.warning("‚ö†Ô∏è **MEDIUM RISK** - Consider additional verification")
            else:
                st.success("‚úÖ **LOW RISK** - Transaction appears legitimate")
            
            # Feature contributions (simplified)
            st.markdown("---")
            st.subheader("Key Factors")
            
            # Show top contributing features
            feature_importance = pd.DataFrame({
                'Feature': feature_names,
                'Value': X_input.values[0]
            })
            
            st.dataframe(
                feature_importance.head(8),
                use_container_width=True,
                hide_index=True
            )

# ============================================================================
# TAB 3: INVESTIGATE CUSTOMER
# ============================================================================

with tab3:
    st.header("üë§ Customer Investigation")
    st.markdown("Analyze transaction history and behavior patterns for a specific customer")
    
    # Load dataset
    df = load_dataset()
    
    if df.empty:
        st.warning("No transaction data available.")
    else:
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("Search Customer")
            
            if 'CUSTOMER_ID' in df.columns:
                # Get unique customers
                customer_ids = sorted(df['CUSTOMER_ID'].unique())
                
                customer_id = st.selectbox(
                    "Select Customer ID",
                    options=customer_ids[:100],  # Limit for performance
                    help="Select a customer to investigate"
                )
                
                if st.button("üîç Load Customer Data", use_container_width=True):
                    st.session_state['selected_customer'] = customer_id
        
        with col2:
            if 'selected_customer' in st.session_state:
                customer_id = st.session_state['selected_customer']
                
                # Filter customer data
                cust_df = df[df['CUSTOMER_ID'] == customer_id].copy()
                
                if len(cust_df) > 0:
                    st.subheader(f"Customer #{customer_id}")
                    
                    # Customer metrics
                    col_a, col_b, col_c, col_d = st.columns(4)
                    
                    with col_a:
                        st.metric("Total Transactions", len(cust_df))
                    
                    with col_b:
                        fraud_count = cust_df['TX_FRAUD'].sum() if 'TX_FRAUD' in cust_df.columns else 0
                        st.metric("Fraud Count", fraud_count)
                    
                    with col_c:
                        avg_amount = cust_df['TX_AMOUNT'].mean()
                        st.metric("Avg Amount", f"${avg_amount:.2f}")
                    
                    with col_d:
                        total_spent = cust_df['TX_AMOUNT'].sum()
                        st.metric("Total Spent", f"${total_spent:.2f}")
                    
                    st.markdown("---")
                    
                    # Transaction timeline
                    st.subheader("Transaction Timeline")
                    
                    cust_df_sorted = cust_df.sort_values('TX_DATETIME')
                    
                    fig = go.Figure()
                    
                    # Legitimate transactions
                    legit = cust_df_sorted[cust_df_sorted['TX_FRAUD'] == 0]
                    fig.add_trace(go.Scatter(
                        x=legit['TX_DATETIME'],
                        y=legit['TX_AMOUNT'],
                        mode='markers',
                        name='Legitimate',
                        marker=dict(color='blue', size=8)
                    ))
                    
                    # Fraudulent transactions
                    if 'TX_FRAUD' in cust_df.columns:
                        fraud = cust_df_sorted[cust_df_sorted['TX_FRAUD'] == 1]
                        if len(fraud) > 0:
                            fig.add_trace(go.Scatter(
                                x=fraud['TX_DATETIME'],
                                y=fraud['TX_AMOUNT'],
                                mode='markers',
                                name='Fraud',
                                marker=dict(color='red', size=12, symbol='x')
                            ))
                    
                    fig.update_layout(
                        title='Transaction History',
                        xaxis_title='Date',
                        yaxis_title='Amount ($)',
                        hovermode='closest',
                        height=400
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Recent transactions table
                    st.subheader("Recent Transactions")
                    
                    display_cols = ['TX_DATETIME', 'TX_AMOUNT', 'TERMINAL_ID']
                    if 'TX_FRAUD' in cust_df.columns:
                        display_cols.append('TX_FRAUD')
                    
                    recent_tx = cust_df_sorted[display_cols].tail(10).sort_values('TX_DATETIME', ascending=False)
                    st.dataframe(recent_tx, use_container_width=True, hide_index=True)
                    
                    # Behavioral insights
                    st.markdown("---")
                    st.subheader("Behavioral Insights")
                    
                    col_x, col_y = st.columns(2)
                    
                    with col_x:
                        # Hour distribution
                        if 'TX_DATETIME' in cust_df.columns:
                            cust_df['hour'] = cust_df['TX_DATETIME'].dt.hour
                            hour_dist = cust_df['hour'].value_counts().sort_index()
                            
                            fig = px.bar(
                                x=hour_dist.index,
                                y=hour_dist.values,
                                labels={'x': 'Hour of Day', 'y': 'Transaction Count'},
                                title='Transaction Distribution by Hour'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                    
                    with col_y:
                        # Amount distribution
                        fig = px.histogram(
                            cust_df,
                            x='TX_AMOUNT',
                            nbins=20,
                            title='Amount Distribution'
                        )
                        fig.update_layout(
                            xaxis_title='Amount ($)',
                            yaxis_title='Frequency'
                        )
                        st.plotly_chart(fig, use_container_width=True)

# ============================================================================
# TAB 4: MODEL EXPLAINABILITY
# ============================================================================

with tab4:
    st.header("üß† Model Explainability & Insights")
    st.markdown("Understand how the fraud detection model makes decisions")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("üìä Model Performance")
        
        # Display key metrics
        if metrics:
            metric_col1, metric_col2 = st.columns(2)
            
            with metric_col1:
                st.metric(
                    "AUPRC",
                    f"{metrics.get('auprc', 0):.4f}",
                    help="Area Under Precision-Recall Curve"
                )
                st.metric(
                    "Test Samples",
                    f"{metrics.get('test_samples', 0):,}"
                )
            
            with metric_col2:
                st.metric(
                    "ROC-AUC",
                    f"{metrics.get('roc_auc', 0):.4f}",
                    help="Area Under ROC Curve"
                )
                st.metric(
                    "Features",
                    metrics.get('feature_count', 0)
                )
        
        st.markdown("---")
        
        # Threshold analysis
        st.subheader("üéØ Threshold Analysis")
        
        st.markdown("""
        The **fraud probability threshold** determines when to flag a transaction:
        
        - **Lower threshold** (e.g., 0.3): Catch more fraud, but more false alarms
        - **Higher threshold** (e.g., 0.7): Fewer false alarms, but miss some fraud
        
        **Current threshold:** {:.2%}
        """.format(threshold))
        
        # Threshold recommendations
        st.info("""
        **Recommended thresholds by use case:**
        
        - üî¥ **High Security** (0.3): Banking, high-value transactions
        - üü° **Balanced** (0.5): E-commerce, moderate risk
        - üü¢ **Low Friction** (0.7): Low-value, high-volume transactions
        """)
    
    with col2:
        st.subheader("üîç Feature Importance")
        
        # Display feature importance
        if os.path.exists('artifacts/feature_importance.png'):
            st.image(
                'artifacts/feature_importance.png',
                caption='Top Features Contributing to Fraud Detection'
            )
        
        # Load and display feature importance table
        if os.path.exists('artifacts/feature_importance.csv'):
            feat_imp = pd.read_csv('artifacts/feature_importance.csv')
            
            st.markdown("**Top 10 Features:**")
            st.dataframe(
                feat_imp.head(10)[['feature', 'importance']],
                use_container_width=True,
                hide_index=True
            )
    
    st.markdown("---")
    
    # Model insights
    st.subheader("üí° Key Insights")
    
    col_a, col_b, col_c = st.columns(3)
    
    with col_a:
        st.markdown("""
        **üéØ Detection Strategy**
        
        - Uses XGBoost classifier
        - Handles class imbalance with SMOTE
        - Focuses on precision-recall tradeoff
        - Real-time feature engineering
        """)
    
    with col_b:
        st.markdown("""
        **üîß Important Features**
        
        - Transaction amount patterns
        - Customer behavior history
        - Time-based features
        - Terminal risk scores
        """)
    
    with col_c:
        st.markdown("""
        **‚ö° Performance**
        
        - High precision for fraud detection
        - Low false positive rate
        - Scalable to millions of transactions
        - Production-ready deployment
        """)
    

    # Export functionality
    st.markdown("---")
    st.subheader("üì• Export Options")
    
    col_export1, col_export2 = st.columns(2)
    
    with col_export1:
        st.markdown("**üìä Download Model Report**")
        st.markdown("Get comprehensive model performance report")
        
        if st.button("üìÑ Generate Report", type="primary", use_container_width=True):
            with st.spinner("Generating report..."):
                report_text = generate_model_report()
                
                st.success("‚úÖ Report generated successfully!")
                
                # Download button
                st.download_button(
                    label="üíæ Download Model Report (.txt)",
                    data=report_text,
                    file_name=f"fraud_model_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    use_container_width=True
                )
                
                # Show preview
                with st.expander("üìÑ Preview Report"):
                    st.text(report_text[:1500] + "\n\n... (truncated for preview)")
    
    with col_export2:
        st.markdown("**‚ö†Ô∏è Download Flagged Transactions**")
        st.markdown("Export high-risk transactions for review")
        
        if st.button("üö® Generate Flagged List", type="primary", use_container_width=True):
            with st.spinner("Analyzing transactions..."):
                df = load_dataset()
                
                if not df.empty:
                    flagged_df = get_flagged_transactions(df, threshold, model, scaler, feature_names)
                    
                    if not flagged_df.empty:
                        st.success(f"‚úÖ Found {len(flagged_df):,} flagged transactions!")
                        
                        # Show preview
                        st.markdown("**Preview (Top 5):**")
                        st.dataframe(flagged_df.head(5), use_container_width=True, hide_index=True)
                        
                        # Risk summary
                        if 'risk_level' in flagged_df.columns:
                            risk_counts = flagged_df['risk_level'].value_counts()
                            st.write(f"üî¥ Critical: {risk_counts.get('Critical', 0)} | "
                                   f"üü† High: {risk_counts.get('High', 0)} | "
                                   f"üü° Medium: {risk_counts.get('Medium', 0)} | "
                                   f"üü¢ Low: {risk_counts.get('Low', 0)}")
                        
                        # Download button
                        csv_data = flagged_df.to_csv(index=False)
                        
                        st.download_button(
                            label=f"üíæ Download All {len(flagged_df):,} Flagged Transactions (.csv)",
                            data=csv_data,
                            file_name=f"flagged_transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    else:
                        st.info("‚úÖ No transactions flagged above the current threshold.")
                else:
                    st.warning("‚ö†Ô∏è No transaction data available to analyze.")
    
    # Additional resources
    st.markdown("---")
    st.subheader("üìö Additional Resources")
    
    with st.expander("‚ÑπÔ∏è About the Model"):
        st.markdown("""
        **Fraud Detection Model Details:**
        
        This model uses **XGBoost** (Extreme Gradient Boosting), an ensemble learning method
        that combines multiple decision trees to make predictions.
        
        **Key Features:**
        - Handles imbalanced data with SMOTE (Synthetic Minority Over-sampling Technique)
        - Uses time-based and behavioral features
        - Trained on historical transaction patterns
        - Optimized for precision-recall balance
        
        **Model Training:**
        - Training Date: {training_date}
        - Features: {feature_count}
        - Random State: {random_state}
        """.format(
            training_date=model_pipeline.get('training_date', 'N/A')[:10],
            feature_count=len(feature_names),
            random_state=model_pipeline.get('random_state', 42)
        ))
    
    with st.expander("üîí Privacy & Security"):
        st.markdown("""
        **Data Privacy:**
        - Customer IDs are anonymized
        - No PII (Personally Identifiable Information) stored
        - Secure model storage
        
        **Security Measures:**
        - Model artifacts encrypted
        - Access control implemented
        - Audit logs maintained
        - Regular security reviews
        """)
    
    with st.expander("üìà Model Improvement"):
        st.markdown("""
        **Continuous Improvement:**
        
        To maintain model accuracy:
        1. Retrain monthly with new data
        2. Monitor performance metrics
        3. Update features based on new fraud patterns
        4. A/B test threshold changes
        5. Collect feedback on false positives/negatives
        
        **Next Steps:**
        - Implement real-time feature store
        - Add SHAP explanations for individual predictions
        - Deploy model monitoring dashboard
        - Set up automated retraining pipeline
        """)

# ============================================================================
# FOOTER
# ============================================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <p><strong>Fraud Detection System v1.0</strong></p>
    <p>Built with Streamlit ‚Ä¢ XGBoost ‚Ä¢ Python</p>
    <p><em>Made By Jeimeen Chaudhari</em></p>
</div>
""", unsafe_allow_html=True)